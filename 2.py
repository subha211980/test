# -*- coding: utf-8 -*-
"""2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-7T7Kyu4LPsiTlCSfdSPyeRZGyAY3TOC
"""

import networkx as nx
import random
import matplotlib.pyplot as plt
import collections

# Example data (replace this with your actual edge list)
your_edge_list = [
    (1, 2), (1, 3), (1, 4), (2, 3), (2, 5), (3, 6),
    (4, 7), (5, 8), (6, 9), (7, 10), (8, 11), (9, 12),
    (1, 13), (1, 14), (13, 14)
]

# Create a graph from your data
G_real = nx.Graph()
G_real.add_edges_from(your_edge_list)

#Reading from txt file:
# Format: Node1 Node2
# A B
# A C
# B C
# B D
# E F

G_from_file = nx.read_edgelist('edges.txt')
nx.draw(G_from_file, with_labels=True, node_color='lightblue', font_weight='bold')
plt.show()

# Read the graph from the GML file
# Note: For integer node IDs, you might need label='id'
G_from_gml = nx.read_gml('network.gml', label='id')
print("Graph loaded from  successfully!")
print("Nodes:", G_from_gml.nodes())
print("Edges:", G_from_gml.edges())

# Draw the graph
nx.draw(G_from_gml, with_labels=True, node_color='lightgreen', font_weight='bold')
plt.show()

import networkx as nx
import matplotlib.pyplot as plt

# --- 1. Define Common and Model-Specific Parameters ---
# Common parameter for all models
num_nodes = 100

# ER (Erdős-Rényi) parameters
p_er = 0.06  # Probability of edge creation

# WS (Watts-Strogatz) parameters
k_ws = 4     # Number of nearest neighbors to connect to
p_ws = 0.1   # Probability of rewiring

# SF (Scale-Free / Barabási-Albert) parameters
m_sf = 3     # Number of edges for a new node to attach

# --- 2. Generate All Three Graphs ---
G_er = nx.erdos_renyi_graph(num_nodes, p_er)
G_ws = nx.watts_strogatz_graph(num_nodes, k_ws, p_ws)
G_sf = nx.barabasi_albert_graph(num_nodes, m_sf)

# --- 3. Set up the Plotting Area ---
# Create a figure with 1 row and 3 columns of subplots
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# --- 4. Draw Each Network in its Subplot ---

# Erdős-Rényi (Random)
ax0 = axes[0]
nx.draw(G_er, ax=ax0, node_size=50, node_color='coral', edge_color='gray')
ax0.set_title(f'Erdős-Rényi (Random)\nn={num_nodes}, p={p_er}')

# Watts-Strogatz (Small-World)
ax1 = axes[1]
# Use a circular layout to highlight its structure
pos_ws = nx.circular_layout(G_ws)
nx.draw(G_ws, pos=pos_ws, ax=ax1, node_size=50, node_color='violet', edge_color='gray')
ax1.set_title(f'Watts-Strogatz (Small-World)\nn={num_nodes}, k={k_ws}, p={p_ws}')

# Scale-Free (Barabási-Albert)
ax2 = axes[2]
nx.draw(G_sf, ax=ax2, node_size=50, node_color='skyblue', edge_color='gray')
ax2.set_title(f'Scale-Free (Hub-Dominated)\nn={num_nodes}, m={m_sf}')

# Display the plots
fig.suptitle('Comparison of Fundamental Network Models', fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make room for suptitle
plt.show()

def plot_degree_distribution(G, ax, color, title):
    """Calculates and plots the degree distribution of a graph on given axes."""
    degree_sequence = sorted([d for n, d in G.degree()], reverse=True)
    degree_count = collections.Counter(degree_sequence)
    deg, cnt = zip(*degree_count.items())

    ax.loglog(deg, cnt, 'o', color=color) # Use loglog for both axes
    ax.set_title(title)
    ax.set_xlabel("Degree (k)")
    ax.set_ylabel("Count P(k)")
    ax.grid(True, which="both", ls="--", linewidth=0.5)

fig, axes = plt.subplots(1, 3, figsize=(20, 6))
fig.suptitle('Degree Distribution Comparison on Log-Log Axes', fontsize=16)

plot_degree_distribution(G_er, axes[0], 'coral', 'Erdős-Rényi')
plot_degree_distribution(G_ws, axes[1], 'violet', 'Watts-Strogatz')
plot_degree_distribution(G_sf, axes[2], 'skyblue', 'Scale-Free')

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

import networkx as nx
import matplotlib.pyplot as plt
import numpy as np

# Let's use a larger BA graph for better analysis
G = nx.barabasi_albert_graph(1000, 3) # 1000 nodes, each new node attaches to 3 existing ones

# --- A. Degree and Degree Distribution ---
# The degree of a node is its number of connections.
degrees = [G.degree(n) for n in G.nodes()]

print(f"Number of nodes: {G.number_of_nodes()}")
print(f"Number of edges: {G.number_of_edges()}")
print(f"Average degree: {np.mean(degrees):.2f}")

# --- B. Average Path Length & Six Degrees of Separation ---
# This concept means that most people are just a few "friend of a friend" steps away from each other.
# In graph theory, it's measured by the average shortest path length.
# NOTE: This can be slow for very large graphs and only works on a connected graph.
if nx.is_connected(G):
    avg_path_len = nx.average_shortest_path_length(G)
    print(f"Average shortest path length: {avg_path_len:.2f}")
else:
    # If the graph is not connected, we can analyze the largest connected component
    largest_cc = max(nx.connected_components(G), key=len)
    G_largest_cc = G.subgraph(largest_cc)
    avg_path_len = nx.average_shortest_path_length(G_largest_cc)
    print(f"Graph is not connected. Average shortest path length of largest component: {avg_path_len:.2f}")


# --- C. Clustering Coefficient ---
# Measures how close a node's neighbors are to being a complete graph (a clique).
# A high value means nodes tend to form tight-knit groups.
avg_clustering = nx.average_clustering(G)
print(f"Average clustering coefficient: {avg_clustering:.2f}")

# You can also get the coefficient for a specific node:
# clustering_node_0 = nx.clustering(G, 0)


# --- D. Degree Distribution Plot ---
# This plot shows how many nodes have each degree.
degree_sequence = sorted([d for n, d in G.degree()], reverse=True)
degree_counts = nx.degree_histogram(G)
degrees_x = range(len(degree_counts))

plt.figure(figsize=(12, 5))

# Plot 1: Standard linear plot
plt.subplot(1, 2, 1)
plt.bar(degrees_x, degree_counts, width=0.80, color="b")
plt.title("Degree Distribution")
plt.xlabel("Degree")
plt.ylabel("Number of Nodes")

# Plot 2: Log-log plot to check for Power Law
# A straight line on a log-log plot suggests a power-law distribution.
plt.subplot(1, 2, 2)
plt.loglog(degrees_x, degree_counts, 'bo')
plt.title("Degree Distribution (Log-Log Scale)")
plt.xlabel("Degree (log)")
plt.ylabel("Number of Nodes (log)")

plt.tight_layout()
plt.show()

import numpy as np

# We'll use the same graph G from the previous section
degrees = [d for n, d in G.degree()]

# <k> is the average degree
k_avg = np.mean(degrees)

# <k^2> is the average of the squared degrees
k2_avg = np.mean([d**2 for d in degrees])

if k_avg > 0:
    critical_threshold = k2_avg / k_avg
    print(f"Average degree <k>: {k_avg:.2f}")
    print(f"Average squared degree <k^2>: {k2_avg:.2f}")
    print(f"Critical Threshold (<k^2>/<k>): {critical_threshold:.2f}")
else:
    print("Graph has no edges; cannot calculate threshold.")

import pandas as pd
import networkx as nx
import collections
import matplotlib.pyplot as plt

# --- Step 1: Create a Dummy CSV File for Demonstration ---
# In a real scenario, you would already have this file.
csv_data = {
    'source': [1, 1, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 1, 1, 13, 15, 15],
    'target': [2, 3, 4, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 16, 1]
}
df_for_csv = pd.DataFrame(csv_data)
df_for_csv.to_csv('network_data.csv', index=False)
print("Created a sample 'network_data.csv' file.")

# --- Step 2: Read the CSV and Build the Graph ---
# Use pandas to read the CSV into a DataFrame
try:
    edge_df = pd.read_csv('network_data.csv')

    # Use networkx to create a graph directly from the pandas DataFrame
    # It assumes the columns for source and target nodes are named 'source' and 'target'
    G_real = nx.from_pandas_edgelist(edge_df, 'source', 'target')
    print("\nSuccessfully created graph from CSV.")

except FileNotFoundError:
    print("Error: 'network_data.csv' not found. Please create it or check the path.")
    exit()

# --- Step 3: Measure Key Properties of Your Graph ---
N = G_real.number_of_nodes()
L = G_real.number_of_edges()
avg_degree = (2 * L) / N
avg_clustering = nx.average_clustering(G_real)

print(f"\n--- Real Graph Properties ---")
print(f"Nodes (N): {N}")
print(f"Edges (L): {L}")
print(f"Average Degree <k>: {avg_degree:.4f}")
print(f"Average Clustering Coefficient C: {avg_clustering:.4f}")

# --- Step 4: Estimate Parameters for Each Model ---
print("\n--- Estimating Model Parameters ---")

# ER Parameters
N_er = N
p_er = avg_degree / (N - 1)
print(f"Erdős-Rényi: N={N_er}, p={p_er:.4f}")

# WS Parameters
N_ws = N
k_ws = round(avg_degree)
if k_ws % 2 != 0: k_ws += 1 # k must be even
print(f"Watts-Strogatz: N={N_ws}, k={k_ws}, p=(requires fitting)")

# SF/BA Parameters
N_sf = N
m_sf = round(avg_degree / 2)
print(f"Scale-Free (BA): N={N_sf}, m={m_sf}")

# --- Step 5: Plot the Real Degree Distribution to Check for Best Fit ---
degree_sequence = sorted([d for n, d in G_real.degree()], reverse=True)
degree_count = collections.Counter(degree_sequence)
deg, cnt = zip(*degree_count.items())

plt.figure(figsize=(8, 6))
plt.loglog(deg, cnt, 'o', color='navy')
plt.title("Degree Distribution of Data from CSV (Log-Log Scale)")
plt.xlabel("Degree (k)")
plt.ylabel("Count P(k)")
plt.grid(True)
plt.show()

"""Step 4: How to Know Which Model Fits Best?
Just calculating parameters isn't enough. You need to determine which model's structure best resembles your data. The best way is to compare the degree distributions.

Plot your real data's degree distribution on a log-log scale.

Check its shape:

If it forms a straight line, your network is likely Scale-Free. The BA model is your best choice.

If it has a clear peak and curves down sharply (like a bell curve), it's either ER or WS.

If it's peaked, check the clustering coefficient:

Generate an ER graph with your estimated parameters (N_er, p_er).

Calculate its average clustering coefficient.

If your real graph's clustering coefficient (avg_clustering) is much higher than the ER model's, then the Watts-Strogatz model is a better fit because it's specifically designed to have high clustering. Otherwise, ER is a reasonable approximation.

"""